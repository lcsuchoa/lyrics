---
title: "Explorando padrões de letras de músicas por meio de análise de cluster e otimização bayesiana"
date: "Última atualização em `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: simplex
    css: src/style.css
    toc: true
    toc_float:
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

```{r echo=F, include=F}
source("src/utils.R")
```

```{r}
data_songs <- read.csv("src/all_songs.csv") %>%
  select(-X) %>%
  mutate(
    lyrics = Slyrics %>%
      gsub("\\d+", "", .) %>%
      tolower() %>%
      gsub("[[:punct:]]", "", .) %>%
      remove_stopwords() %>%
      as.character()
  )

data_artists <- read.csv("src/all_artists.csv")
```

## Gabarito

```{r}
data <- read.csv("src/data_gabarito.csv")

gabarito <- data[1,] %>%
  t() %>%
  as.data.frame() %>%
  rename(sentimentos = 1) %>%
  mutate(
    anger = ifelse(grepl("Raiva", sentimentos), 1, 0),
    anticipation = ifelse(grepl("Antecipação", sentimentos), 1, 0),
    disgust = ifelse(grepl("Desgosto", sentimentos), 1, 0),
    fear = ifelse(grepl("Medo", sentimentos), 1, 0),
    joy = ifelse(grepl("Alegria", sentimentos), 1, 0),
    sadness = ifelse(grepl("Tristeza", sentimentos), 1, 0),
    surprise = ifelse(grepl("Surpresa", sentimentos), 1, 0),
    trust = ifelse(grepl("Confiança", sentimentos), 1, 0),
    negative = ifelse(grepl("Negativo", sentimentos), 1, 0),
    positive = ifelse(grepl("Positivo", sentimentos), 1, 0),
  ) %>%
  select(-sentimentos) %>%
  mutate(across(everything(), as.factor))

row.names(gabarito) <- NULL
data_gabarito <- cbind(data_songs, gabarito) %>%
  mutate(
    across(anger:positive, ~ as.numeric(as.character(.))),
    lyrics = data_songs$lyrics
  ) %>%
  distinct(Slink, .keep_all = TRUE)

rm(data, gabarito)
```

```{r}
data_gabarito %>%
  filter(rowSums((data_gabarito %>% select(anger:positive)) != 0) > 0)
```

```{r}
data_songs <- data_songs %>% distinct(Slink, .keep_all = TRUE)
```


## Análise exploratória

##### Frequência de músicas anotadas por sentimento
```{r}
data_gabarito %>%
  reframe(across(anger:positive, sum)) %>%
  pivot_longer(cols = everything(), names_to = "sentimento", values_to = "count") %>%
  mutate(sentimento = labels_pt[sentimento]) %>%
  arrange(desc(count)) %>%
  mutate(sentimento = factor(sentimento, levels = sentimento)) %>%
  ggplot(aes(x = sentimento, y = count)) +
  geom_bar(stat = "identity", fill = "darkblue") +
  geom_text(aes(label = count), vjust = 2, size = 3, color = "white") + 
  scale_y_continuous(limits = c(0, 300)) +
  theme_minimal() +
  labs(x = "", y = "Frequência", title = "") +
  theme(axis.text.x = element_text())
```

##### Matriz de correlação entre sentimentos
```{r}
correlation_matrix <- cor(data_gabarito %>% select(anger:positive))
hc <- hclust(dist(1 - correlation_matrix))
ordered_matrix <- correlation_matrix[hc$order, hc$order]
long_correlation_matrix <- melt(ordered_matrix)

long_correlation_matrix %>%
  ggplot(aes(x = Var2, y = Var1, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(name = "Correlação",  mid = "white",  high = "darkblue",
                       low = "darkorange",  midpoint = 0, limit = c(-1, 1), 
                       breaks = c(-1, -0.5, 0, 0.5, 1)) +
  theme_minimal() +
  labs(x = "", y = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), 
        axis.text.y = element_text(hjust = 1)) +
  scale_x_discrete(labels = labels_pt) +
  scale_y_discrete(labels = labels_pt)

rm(correlation_matrix, hc, ordered_matrix, long_correlation_matrix)
```

##### Proporção de sentimentos por gênero
```{r}
data_gabarito %>%
  left_join(data_artists, by="Alink") %>%
  select(-c(X, Asongs, Apopularity)) %>%
  distinct() %>%
  separate_rows(Agenres, sep = ";\\s*") %>%
  group_by(Agenres) %>%
  reframe(
    n = n(),
    across(anger:positive, mean)
  ) %>%
  mutate(
    total = anger+anticipation+disgust+fear+joy+sadness+surprise+trust+negative+positive,
    across(anger:positive, ~ .x / total)
  ) %>%
  filter(n >= 20) %>%
  arrange(desc(n)) %>%
  pivot_longer(
    cols = anger:positive,
    names_to = "sentiment",
    values_to = "percentage"
  ) %>%
  mutate(sentiment = factor(sentiment, levels = c("positive", "joy", "trust", "surprise", "anticipation", "fear", "anger", "sadness", "disgust", "negative"))) %>%
  ggplot(aes(x = Agenres, y = percentage, fill = sentiment)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)), 
            position = position_stack(vjust = 0.5), 
            color = "white", 
            size = 3) +
  scale_fill_manual(values = colorRampPalette(colors = c("darkblue", "darkgrey", "darkorange"))(10), labels = labels_pt) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "Gênero", y = "Percentual do Sentimento", fill = "Sentimento") +
  theme_minimal()
```


## Pacote syuzhet

[!] Como definir o valor de corte?

```{r}
syuzhet <- future_map_dfr(data_gabarito$lyrics, ~syuzhet_classification(., 0.05)) %>%
  mutate(across(everything(), as.factor))
data_syuzhet <- cbind(data_songs, syuzhet)
```

### Matriz de confusão

```{r}
confusionMatrix(
  unlist(data_syuzhet[, "positive"]),
  unlist(data_gabarito[, "positive"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "negative"]),
  unlist(data_gabarito[, "negative"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "anger"]),
  unlist(data_gabarito[, "anger"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "anticipation"]),
  unlist(data_gabarito[, "anticipation"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "disgust"]),
  unlist(data_gabarito[, "disgust"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "fear"]),
  unlist(data_gabarito[, "fear"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "joy"]),
  unlist(data_gabarito[, "joy"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "sadness"]),
  unlist(data_gabarito[, "sadness"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "surprise"]),
  unlist(data_gabarito[, "surprise"] %>% as.factor())
)

confusionMatrix(
  unlist(data_syuzhet[, "trust"]),
  unlist(data_gabarito[, "trust"] %>% as.factor())
)
```


## TF IDF
```{r}
tfidf <- DocumentTermMatrix(data_gabarito$lyrics) %>% 
  weightTfIdf() %>%
  as.matrix() %>%
  as.data.frame()

data_tfidf <- cbind(tfidf, data_gabarito %>% select(anger:positive))
colnames(data_tfidf) <- clean_names(colnames(data_tfidf))

data_tfidf <- data_tfidf %>%
  mutate(across((ncol(data_tfidf)-9):ncol(data_tfidf), ~ as.factor(ifelse(. > 0.5, "Yes", "No"))))
```


## Random Forest

### Positivo
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(positive)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(positive ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = positive, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = positive, estimate = .pred_class)
print(conf_matrix)
```


### Negativo
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(negative)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(negative ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = negative, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = negative, estimate = .pred_class)
print(conf_matrix)
```

### Raiva
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(anger)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(anger ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = anger, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = anger, estimate = .pred_class)
print(conf_matrix)
```

### Antecipação
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(anticipation)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(anticipation ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = anticipation, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = anticipation, estimate = .pred_class)
print(conf_matrix)
```

### Desgosto
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(disgust)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(disgust ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = disgust, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = disgust, estimate = .pred_class)
print(conf_matrix)
```

### Medo
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(fear)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(fear ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = fear, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = fear, estimate = .pred_class)
print(conf_matrix)
```

### Alegria
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(joy)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(joy ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = joy, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = joy, estimate = .pred_class)
print(conf_matrix)
```

### Tristeza
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(sadness)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(sadness ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = sadness, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = sadness, estimate = .pred_class)
print(conf_matrix)
```

### Surpresa
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(surprise)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(surprise ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = surprise, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = surprise, estimate = .pred_class)
print(conf_matrix)
```

### Confiança
```{r}
set.seed(7)

# Selecionar apenas as colunas de TF-IDF e a coluna de resposta
tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(trust)
model_data <- bind_cols(tfidf_cols, response_col)

# Separar os dados em treino e teste
data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar o modelo de random forest
rf_model <- rand_forest(mode = "classification", trees = 1000) %>%
  set_engine("ranger")

# Especificar a receita de pré-processamento
recipe <- recipe(trust ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Treinar o modelo
rf_fit <- wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
predictions <- rf_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = factor(ifelse(.pred_Yes > 0.5, "Yes", "No"), levels = c("No", "Yes")))

# Avaliar o modelo com as métricas personalizadas
custom_metrics <- metric_set(roc_auc, accuracy, precision, recall, f_meas)
final_metrics <- custom_metrics(predictions, truth = trust, estimate = .pred_class, .pred_Yes)
print(final_metrics)

# Calcular a matriz de confusão
conf_matrix <- conf_mat(predictions, truth = trust, estimate = .pred_class)
print(conf_matrix)
```




## Otimização Bayesiana

### Positivo
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(positive)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(positive ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = positive, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = positive, .pred_Yes),
    final_predictions %>% f_meas(truth = positive, estimate = .pred_class),
    final_predictions %>% precision(truth = positive, estimate = .pred_class),
    final_predictions %>% recall(truth = positive, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Negativo
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(negative)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(negative ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = negative, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = negative, .pred_Yes),
    final_predictions %>% f_meas(truth = negative, estimate = .pred_class),
    final_predictions %>% precision(truth = negative, estimate = .pred_class),
    final_predictions %>% recall(truth = negative, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Raiva
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(anger)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(anger ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = anger, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = anger, .pred_Yes),
    final_predictions %>% f_meas(truth = anger, estimate = .pred_class),
    final_predictions %>% precision(truth = anger, estimate = .pred_class),
    final_predictions %>% recall(truth = anger, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Antecipação
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(anticipation)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(anticipation ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = anticipation, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = anticipation, .pred_Yes),
    final_predictions %>% f_meas(truth = anticipation, estimate = .pred_class),
    final_predictions %>% precision(truth = anticipation, estimate = .pred_class),
    final_predictions %>% recall(truth = anticipation, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Desgosto
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(disgust)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(disgust ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = disgust, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = disgust, .pred_Yes),
    final_predictions %>% f_meas(truth = disgust, estimate = .pred_class),
    final_predictions %>% precision(truth = disgust, estimate = .pred_class),
    final_predictions %>% recall(truth = disgust, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Medo
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(fear)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(fear ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = fear, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = fear, .pred_Yes),
    final_predictions %>% f_meas(truth = fear, estimate = .pred_class),
    final_predictions %>% precision(truth = fear, estimate = .pred_class),
    final_predictions %>% recall(truth = fear, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Alegria
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(joy)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(joy ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = joy, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = joy, .pred_Yes),
    final_predictions %>% f_meas(truth = joy, estimate = .pred_class),
    final_predictions %>% precision(truth = joy, estimate = .pred_class),
    final_predictions %>% recall(truth = joy, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Tristeza
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(sadness)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(sadness ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = sadness, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = sadness, .pred_Yes),
    final_predictions %>% f_meas(truth = sadness, estimate = .pred_class),
    final_predictions %>% precision(truth = sadness, estimate = .pred_class),
    final_predictions %>% recall(truth = sadness, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Surpresa
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(surprise)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(surprise ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = surprise, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = surprise, .pred_Yes),
    final_predictions %>% f_meas(truth = surprise, estimate = .pred_class),
    final_predictions %>% precision(truth = surprise, estimate = .pred_class),
    final_predictions %>% recall(truth = surprise, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```

### Confiança
```{r}
set.seed(7)

tfidf_cols <- data_tfidf %>% select(1:(ncol(data_tfidf)-10))
response_col <- data_tfidf %>% select(trust)
model_data <- bind_cols(tfidf_cols, response_col)

data_split <- initial_split(model_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Especificar a receita de pré-processamento
recipe <- recipe(trust ~ ., data = train_data) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_predictors())

# Definir o modelo com hiperparâmetros a serem otimizados
rf_model <- rand_forest(
  mode = "classification",
  trees = tune(),
  mtry = tune(),
  min_n = tune()
) %>% 
  set_engine("ranger")

# Criar o fluxo de trabalho
wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_model)

# Definir a grade de hiperparâmetros
rf_grid <- parameters(
  trees(range = c(500, 2000)),
  mtry(range = c(1, ncol(train_data) - 1)),
  min_n(range = c(1, 10))
)

# Definir a estratégia de resampling
cv_folds <- vfold_cv(train_data, v = 5)

# Otimização bayesiana
set.seed(7)
tune_results <- tune_bayes(
  wf,
  resamples = cv_folds,
  param_info = rf_grid,
  iter = 50,
  metrics = metric_set(roc_auc, accuracy, precision, recall, f_meas),
  control = control_bayes(verbose = TRUE)
)

# Selecionar o melhor conjunto de hiperparâmetros
best_params <- select_best(tune_results, metric = "accuracy")

# Ajustar o melhor modelo
final_rf_model <- finalize_model(rf_model, best_params)

# Atualizar o workflow com os melhores hiperparâmetros
final_wf <- wf %>%
  finalize_workflow(best_params)

# Treinar o modelo final
final_fit <- final_wf %>%
  fit(data = train_data)

# Fazer previsões no conjunto de teste
final_predictions <- final_fit %>%
  predict(new_data = test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  mutate(.pred_class = ifelse(.pred_Yes > 0.5, "Yes", "No"))

# Avaliar o modelo final
final_metrics <- final_predictions %>%
  metrics(truth = trust, estimate = .pred_class) %>%
  bind_rows(
    final_predictions %>% roc_auc(truth = trust, .pred_Yes),
    final_predictions %>% f_meas(truth = trust, estimate = .pred_class),
    final_predictions %>% precision(truth = trust, estimate = .pred_class),
    final_predictions %>% recall(truth = trust, estimate = .pred_class)
  )

# Mostrar as métricas de avaliação
print(final_metrics)

```
